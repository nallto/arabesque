<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>シンプルな映像処理アプリ</title>
    <style>
        body {
            margin: 0;
            padding: 0;
            width: 100vw;
            height: 100vh;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            font-family: sans-serif;
            background-color: #f0f0f0;
        }
        
        h1 {
            margin-bottom: 20px;
            color: #333;
        }
        
        .container {
            position: relative;
            margin: 0 auto;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
            border-radius: 8px;
            overflow: hidden;
        }
        
        video, canvas {
            position: absolute;
            top: 0;
            left: 0;
        }
        
        #status {
            margin-top: 20px;
            padding: 10px;
            background-color: #4CAF50;
            color: white;
            border-radius: 4px;
            text-align: center;
        }
        
        .button {
            margin-top: 20px;
            padding: 10px 20px;
            background-color: #2196F3;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 16px;
        }
        
        .button:hover {
            background-color: #0b7dda;
        }
        
        .button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }
        
        .controls {
            margin-top: 20px;
            display: flex;
            gap: 10px;
        }
        
        .filter-option {
            padding: 8px 15px;
            background-color: #333;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
        }
        
        .filter-option.active {
            background-color: #4CAF50;
        }
    </style>
</head>
<body>
    <h1>カメラ映像処理アプリ</h1>
    
    <div class="container">
        <video id="video" width="640" height="480"></video>
        <canvas id="overlay" width="640" height="480"></canvas>
    </div>
    
    <div id="status">カメラを準備中...</div>
    
    <button id="startButton" class="button">開始</button>
    
    <div class="controls">
        <button class="filter-option active" data-filter="normal">通常</button>
        <button class="filter-option" data-filter="grayscale">グレースケール</button>
        <button class="filter-option" data-filter="edges">エッジ検出</button>
        <button class="filter-option" data-filter="threshold">しきい値処理</button>
        <button class="filter-option" data-filter="invert">色反転</button>
    </div>
    
    <script>
        // DOM要素
        const video = document.getElementById('video');
        const overlay = document.getElementById('overlay');
        const context = overlay.getContext('2d');
        const statusText = document.getElementById('status');
        const startButton = document.getElementById('startButton');
        const filterButtons = document.querySelectorAll('.filter-option');
        
        // 状態変数
        let isRunning = false;
        let currentFilter = 'normal';
        
        // カメラ設定
        async function setupCamera() {
            statusText.textContent = 'カメラへのアクセスを要求中...';
            
            try {
                // シンプルな制約を使用
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: true,
                    audio: false
                });
                
                // ビデオ要素に接続
                video.srcObject = stream;
                
                // ビデオの属性を明示的に設定
                video.setAttribute('autoplay', '');
                video.setAttribute('playsinline', ''); // iOSのSafariでインライン再生を許可
                video.setAttribute('muted', '');
                
                return new Promise((resolve) => {
                    // メタデータ読み込み完了を待機
                    video.onloadedmetadata = () => {
                        // 再生を明示的に開始
                        video.play().then(() => {
                            statusText.textContent = 'カメラの準備完了！';
                            resolve(video);
                        }).catch(e => {
                            console.error('ビデオ再生エラー:', e);
                            statusText.textContent = 'ビデオ再生エラー: ' + e.message;
                            statusText.style.backgroundColor = '#f44336';
                        });
                    };
                });
            } catch (error) {
                console.error('カメラアクセスエラー:', error);
                statusText.textContent = 'カメラアクセスエラー: ' + error.message;
                statusText.style.backgroundColor = '#f44336';
                throw error;
            }
        }
        
        // 映像処理ループ
        function processVideo() {
            if (!isRunning) return;
            
            // キャンバスに映像を描画
            context.drawImage(video, 0, 0, overlay.width, overlay.height);
            
            // 選択されたフィルターを適用
            applyFilter(currentFilter);
            
            // 顔検出の代わりに簡単な特徴点をシミュレート
            if (currentFilter === 'edges' || currentFilter === 'threshold') {
                drawSimulatedFacePoints();
            }
            
            // ステータス表示
            context.fillStyle = 'rgba(0, 0, 0, 0.5)';
            context.fillRect(10, 10, 230, 30);
            context.fillStyle = 'white';
            context.font = '16px Arial';
            context.fillText(`フィルター: ${getFilterName(currentFilter)}`, 20, 30);
            
            requestAnimationFrame(processVideo);
        }
        
        // フィルター名の日本語表示
        function getFilterName(filter) {
            const names = {
                'normal': '通常',
                'grayscale': 'グレースケール',
                'edges': 'エッジ検出',
                'threshold': 'しきい値処理',
                'invert': '色反転'
            };
            return names[filter] || filter;
        }
        
        // 映像フィルター適用
        function applyFilter(filter) {
            const imageData = context.getImageData(0, 0, overlay.width, overlay.height);
            const data = imageData.data;
            
            switch (filter) {
                case 'grayscale':
                    for (let i = 0; i < data.length; i += 4) {
                        const avg = (data[i] + data[i + 1] + data[i + 2]) / 3;
                        data[i] = avg;     // R
                        data[i + 1] = avg; // G
                        data[i + 2] = avg; // B
                    }
                    break;
                    
                case 'invert':
                    for (let i = 0; i < data.length; i += 4) {
                        data[i] = 255 - data[i];         // R
                        data[i + 1] = 255 - data[i + 1]; // G
                        data[i + 2] = 255 - data[i + 2]; // B
                    }
                    break;
                    
                case 'threshold':
                    for (let i = 0; i < data.length; i += 4) {
                        const avg = (data[i] + data[i + 1] + data[i + 2]) / 3;
                        const val = avg > 128 ? 255 : 0;
                        data[i] = val;     // R
                        data[i + 1] = val; // G
                        data[i + 2] = val; // B
                    }
                    break;
                    
                case 'edges':
                    // 簡易的なエッジ検出（差分検出）
                    const tempCanvas = document.createElement('canvas');
                    const tempContext = tempCanvas.getContext('2d');
                    tempCanvas.width = overlay.width;
                    tempCanvas.height = overlay.height;
                    
                    // グレースケール化して一時キャンバスに保存
                    tempContext.drawImage(video, 0, 0, overlay.width, overlay.height);
                    const tempData = tempContext.getImageData(0, 0, overlay.width, overlay.height);
                    const tempPixels = tempData.data;
                    
                    for (let i = 0; i < tempPixels.length; i += 4) {
                        const avg = (tempPixels[i] + tempPixels[i + 1] + tempPixels[i + 2]) / 3;
                        tempPixels[i] = avg;
                        tempPixels[i + 1] = avg;
                        tempPixels[i + 2] = avg;
                    }
                    
                    tempContext.putImageData(tempData, 0, 0);
                    
                    // 差分を計算して輪郭を強調
                    for (let y = 1; y < overlay.height - 1; y++) {
                        for (let x = 1; x < overlay.width - 1; x++) {
                            const idx = (y * overlay.width + x) * 4;
                            const idxLeft = (y * overlay.width + (x - 1)) * 4;
                            const idxRight = (y * overlay.width + (x + 1)) * 4;
                            const idxUp = ((y - 1) * overlay.width + x) * 4;
                            const idxDown = ((y + 1) * overlay.width + x) * 4;
                            
                            // 周囲のピクセルとの差分を計算
                            const diff = Math.abs(tempPixels[idx] - tempPixels[idxLeft]) +
                                        Math.abs(tempPixels[idx] - tempPixels[idxRight]) +
                                        Math.abs(tempPixels[idx] - tempPixels[idxUp]) +
                                        Math.abs(tempPixels[idx] - tempPixels[idxDown]);
                            
                            // 差分が大きいほど輪郭（エッジ）と判断
                            const edge = diff > 100 ? 255 : 0;
                            
                            data[idx] = edge;
                            data[idx + 1] = edge;
                            data[idx + 2] = edge;
                        }
                    }
                    break;
                
                case 'normal':
                default:
                    // 何もしない（元の映像をそのまま表示）
                    break;
            }
            
            context.putImageData(imageData, 0, 0);
        }
        
        // 顔特徴点の代わりに簡単な点や線を描画（シミュレーション）
        function drawSimulatedFacePoints() {
            // デバッグ情報を表示
            context.fillStyle = 'rgba(255, 255, 255, 0.7)';
            context.fillRect(10, overlay.height - 60, 300, 50);
            context.fillStyle = 'black';
            context.font = '12px Arial';
            context.fillText(`カメラ接続状態: ${video.srcObject ? '接続中' : '未接続'}`, 15, overlay.height - 40);
            context.fillText(`動作状態: ${isRunning ? '実行中' : '停止中'}`, 15, overlay.height - 25);
            
            // 中心座標（カメラ映像の中央付近）
            const centerX = overlay.width / 2;
            const centerY = overlay.height / 2;
            
            // 顔の大きさ（楕円）
            const faceWidth = overlay.width / 3;
            const faceHeight = overlay.height / 2.2;
            
            // 特徴点の色
            context.fillStyle = 'rgba(0, 255, 0, 0.8)';
            context.strokeStyle = 'rgba(0, 255, 0, 0.8)';
            context.lineWidth = 2;
            
            // 顔の輪郭（楕円）
            context.beginPath();
            context.ellipse(centerX, centerY, faceWidth / 2, faceHeight / 2, 0, 0, 2 * Math.PI);
            context.stroke();
            
            // 目（左）
            const leftEyeX = centerX - faceWidth / 5;
            const eyeY = centerY - faceHeight / 8;
            context.beginPath();
            context.ellipse(leftEyeX, eyeY, faceWidth / 12, faceHeight / 20, 0, 0, 2 * Math.PI);
            context.stroke();
            
            // 目（右）
            const rightEyeX = centerX + faceWidth / 5;
            context.beginPath();
            context.ellipse(rightEyeX, eyeY, faceWidth / 12, faceHeight / 20, 0, 0, 2 * Math.PI);
            context.stroke();
            
            // 鼻
            context.beginPath();
            context.moveTo(centerX, eyeY + faceHeight / 10);
            context.lineTo(centerX - faceWidth / 20, centerY + faceHeight / 15);
            context.lineTo(centerX + faceWidth / 20, centerY + faceHeight / 15);
            context.closePath();
            context.stroke();
            
            // 口
            const mouthY = centerY + faceHeight / 4;
            context.beginPath();
            context.moveTo(centerX - faceWidth / 5, mouthY);
            context.quadraticCurveTo(centerX, mouthY + faceHeight / 20, centerX + faceWidth / 5, mouthY);
            context.stroke();
            
            // 顔の特徴点（ランダム）
            const numPoints = 30;
            for (let i = 0; i < numPoints; i++) {
                // 楕円上の点を生成
                const angle = Math.random() * 2 * Math.PI;
                const r1 = Math.random() * 0.8 + 0.2; // 0.2〜1.0
                const x = centerX + Math.cos(angle) * (faceWidth / 2) * r1;
                const y = centerY + Math.sin(angle) * (faceHeight / 2) * r1;
                
                // 点を描画
                context.beginPath();
                context.arc(x, y, 2, 0, 2 * Math.PI);
                context.fill();
            }
        }
        
        // アプリの起動
        async function startApp() {
            try {
                if (!isRunning) {
                    await setupCamera();
                    isRunning = true;
                    processVideo();
                    startButton.textContent = '停止';
                    statusText.textContent = '映像処理中...';
                } else {
                    isRunning = false;
                    if (video.srcObject) {
                        video.srcObject.getTracks().forEach(track => track.stop());
                        video.srcObject = null;
                    }
                    context.clearRect(0, 0, overlay.width, overlay.height);
                    startButton.textContent = '開始';
                    statusText.textContent = '停止中';
                }
            } catch (error) {
                console.error('アプリ起動エラー:', error);
            }
        }
        
        // フィルター切り替え
        function changeFilter(event) {
            if (!event.target.classList.contains('filter-option')) return;
            
            // 現在のフィルターボタンから active クラスを削除
            filterButtons.forEach(button => button.classList.remove('active'));
            
            // 選択されたボタンに active クラスを追加
            event.target.classList.add('active');
            
            // フィルターを設定
            currentFilter = event.target.dataset.filter;
        }
        
        // イベントリスナー
        startButton.addEventListener('click', startApp);
        document.querySelector('.controls').addEventListener('click', changeFilter);
        
        // ページ読み込み時のカメラセットアップを削除し、ボタンクリック時のみ実行するように変更
        window.addEventListener('load', () => {
            statusText.textContent = '「開始」ボタンをクリックしてカメラを開始してください';
            startButton.disabled = false;
        });
    </script>
</body>
</html>
