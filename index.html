<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>リアルタイム顔特徴点検出</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/face-api.js/0.22.2/face-api.min.js"></script>
    <style>
        body {
            margin: 0;
            padding: 0;
            width: 100vw;
            height: 100vh;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background-color: #f0f0f0;
        }
        .container {
            position: relative;
            margin: 20px;
        }
        #video {
            width: 640px;
            height: 480px;
            border-radius: 10px;
            object-fit: cover;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
        }
        #overlay {
            position: absolute;
            top: 0;
            left: 0;
            width: 640px;
            height: 480px;
            z-index: 10;
        }
        .controls {
            margin-top: 20px;
            display: flex;
            gap: 10px;
        }
        button {
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
            background-color: #4CAF50;
            color: white;
            font-size: 16px;
            cursor: pointer;
            transition: background-color 0.3s;
        }
        button:hover {
            background-color: #45a049;
        }
        #status {
            margin-top: 10px;
            color: #333;
            font-size: 16px;
        }
    </style>
</head>
<body>
    <h1>リアルタイム顔特徴点検出</h1>
    <div class="container">
        <video id="video" autoplay muted></video>
        <canvas id="overlay"></canvas>
    </div>
    <div class="controls">
        <button id="startButton">カメラを開始</button>
        <button id="stopButton" disabled>停止</button>
    </div>
    <div id="status">モデルを読み込んでいます...</div>

    <script>
        const video = document.getElementById('video');
        const overlay = document.getElementById('overlay');
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const statusText = document.getElementById('status');
        
        let isRunning = false;
        let stream = null;

        // キャンバスのサイズをビデオに合わせる
        overlay.width = 640;
        overlay.height = 480;

        // FaceAPIのモデルを読み込む
        Promise.all([
            faceapi.nets.tinyFaceDetector.loadFromUri('https://cdnjs.cloudflare.com/ajax/libs/face-api.js/0.22.2/models'),
            faceapi.nets.faceLandmark68Net.loadFromUri('https://cdnjs.cloudflare.com/ajax/libs/face-api.js/0.22.2/models')
        ]).then(() => {
            statusText.textContent = 'モデルの読み込みが完了しました。カメラを開始してください。';
            startButton.disabled = false;
        }).catch(err => {
            statusText.textContent = 'モデルの読み込みに失敗しました: ' + err.message;
        });

        // カメラ開始ボタンのイベントリスナー
        startButton.addEventListener('click', async () => {
            try {
                stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        width: 640,
                        height: 480,
                        facingMode: 'user'
                    }
                });
                video.srcObject = stream;
                isRunning = true;
                startDetection();
                startButton.disabled = true;
                stopButton.disabled = false;
                statusText.textContent = '顔特徴点を検出中...';
            } catch (err) {
                statusText.textContent = 'カメラへのアクセスに失敗しました: ' + err.message;
            }
        });

        // 停止ボタンのイベントリスナー
        stopButton.addEventListener('click', () => {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                video.srcObject = null;
                isRunning = false;
                startButton.disabled = false;
                stopButton.disabled = true;
                statusText.textContent = '停止しました。カメラを再開するには「カメラを開始」ボタンを押してください。';
                
                // キャンバスをクリア
                const ctx = overlay.getContext('2d');
                ctx.clearRect(0, 0, overlay.width, overlay.height);
            }
        });

        // 顔検出とランドマーク描画の関数
        async function startDetection() {
            if (!isRunning) return;

            const detections = await faceapi.detectAllFaces(
                video, 
                new faceapi.TinyFaceDetectorOptions()
            ).withFaceLandmarks();

            const ctx = overlay.getContext('2d');
            ctx.clearRect(0, 0, overlay.width, overlay.height);
            
            // すべての検出された顔に対して処理
            detections.forEach(detection => {
                // 顔の輪郭を描画
                ctx.beginPath();
                ctx.lineWidth = 2;
                ctx.strokeStyle = 'rgba(0, 255, 0, 0.8)';
                ctx.rect(
                    detection.detection.box.x,
                    detection.detection.box.y,
                    detection.detection.box.width,
                    detection.detection.box.height
                );
                ctx.stroke();
                
                // 顔のランドマークを描画
                const landmarks = detection.landmarks;
                const positions = landmarks.positions;
                
                // 特徴点のグループを異なる色で描画
                drawPointsGroup(ctx, positions.slice(0, 17), 'rgba(255, 0, 0, 0.8)');  // 顔の輪郭
                drawPointsGroup(ctx, positions.slice(17, 27), 'rgba(0, 0, 255, 0.8)'); // 眉毛
                drawPointsGroup(ctx, positions.slice(27, 36), 'rgba(255, 255, 0, 0.8)'); // 鼻
                drawPointsGroup(ctx, positions.slice(36, 48), 'rgba(0, 255, 255, 0.8)'); // 目
                drawPointsGroup(ctx, positions.slice(48, 68), 'rgba(255, 0, 255, 0.8)'); // 口
            });
            
            // 次のフレームで検出を続ける
            requestAnimationFrame(startDetection);
        }

        // 特徴点のグループを描画する関数
        function drawPointsGroup(ctx, points, color) {
            ctx.fillStyle = color;
            
            // 各点を描画
            points.forEach(point => {
                ctx.beginPath();
                ctx.arc(point.x, point.y, 2, 0, 2 * Math.PI);
                ctx.fill();
            });
            
            // 点同士を線で接続
            if (points.length > 1) {
                ctx.strokeStyle = color;
                ctx.lineWidth = 1;
                ctx.beginPath();
                ctx.moveTo(points[0].x, points[0].y);
                
                for (let i = 1; i < points.length; i++) {
                    ctx.lineTo(points[i].x, points[i].y);
                }
                
                ctx.stroke();
            }
        }
    </script>
</body>
</html>
